{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cap_proj_NER_mvp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNa1rXrkEuQvmMrHc9pP6Vd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yilin2718/search-product-reviews-weaviate/blob/main/cap_proj_NER_mvp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spacy based entity extraction and ambiguation.\n",
        "\n",
        "100K products and 100K vendors used in the MVP. \n",
        "\n",
        "Based on:\n",
        "\n",
        "Concise Concepts:   \n",
        "https://github.com/Pandora-Intelligence/concise-concepts\n",
        "\n",
        "POS tagging:\n",
        "https://spacy.io/usage/linguistic-features\n",
        "\n",
        "Spacy Span Categorizer (detecting entities within entities)\n",
        "https://spacy.io/api/spancategorizer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oVdldfJveMpo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znhfuVbaeLzu",
        "outputId": "da511f72-667e-4788-d794-1df33e847921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/FBproject/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlp9-AiweZnK",
        "outputId": "cc6e570c-9ccb-4a3a-a04b-c6c300487cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/FBproject\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yIBuMlp4gxWC",
        "outputId": "ed090acb-7788-455b-d197-4925bb6b6768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/FBproject'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Spacy==3.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eneSsJTfe4Lo",
        "outputId": "8ebba3e5-4c2f-4e42-8815-f6af3e0636d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Spacy==3.2\n",
            "  Downloading spacy-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 28.1 MB/s \n",
            "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from Spacy==3.2) (4.64.0)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Collecting thinc<8.1.0,>=8.0.12\n",
            "  Downloading thinc-8.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (653 kB)\n",
            "\u001b[K     |████████████████████████████████| 653 kB 52.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from Spacy==3.2) (57.4.0)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 51.6 MB/s \n",
            "\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from Spacy==3.2) (0.9.1)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from Spacy==3.2) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from Spacy==3.2) (3.0.6)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 65.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from Spacy==3.2) (2.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from Spacy==3.2) (21.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from Spacy==3.2) (1.21.6)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from Spacy==3.2) (1.0.7)\n",
            "Collecting typing-extensions<4.0.0.0,>=3.7.4\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (457 kB)\n",
            "\u001b[K     |████████████████████████████████| 457 kB 54.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from Spacy==3.2) (2.0.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from Spacy==3.2) (0.4.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->Spacy==3.2) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->Spacy==3.2) (3.0.8)\n",
            "Collecting smart-open<6.0.0,>=5.0.0\n",
            "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->Spacy==3.2) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->Spacy==3.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->Spacy==3.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->Spacy==3.2) (3.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->Spacy==3.2) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->Spacy==3.2) (2.0.1)\n",
            "Installing collected packages: typing-extensions, catalogue, typer, srsly, smart-open, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, Spacy\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 6.0.0\n",
            "    Uninstalling smart-open-6.0.0:\n",
            "      Successfully uninstalled smart-open-6.0.0\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: Spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed Spacy-3.2.0 catalogue-2.0.7 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 smart-open-5.2.1 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 thinc-8.0.15 typer-0.4.1 typing-extensions-3.10.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NER customization**\n"
      ],
      "metadata": {
        "id": "zi66pB19jaHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#helper functions\n",
        "# we have some bad data - name is float so need to check for it\n",
        "\n",
        "def convert_to_lowerCase (df_in, col_name):\n",
        "  for i in range(len(df_in)):\n",
        "    if isinstance (df_in.iloc[i][col_name], float):\n",
        "      print (i, df_in.iloc[i][col_name])\n",
        "      c\n",
        "      df_in.iloc[i][col_name] = str( df_in.iloc[i][col_name] )\n",
        "    df_in.iloc[i][col_name] = str.lower(df_in.iloc[i][col_name])\n",
        "  return df_in\n",
        "\n",
        "all_prods_df = convert_to_lowerCase (all_prods_df, 'productName')\n",
        "all_vendors_df = convert_to_lowerCase (all_vendors_df, 'name')\n",
        "all_cats_df = convert_to_lowerCase (all_cats_df, 'name')\n",
        "#all_prods_df['productName'] = all_prods_df['productName'].apply(str.lower)\n",
        "#all_cats_df ['name'] = all_cats_df['name'].apply(str.lower)\n",
        "#all_vendors_df ['name'] = all_vendors_df['name'].apply(str.lower)"
      ],
      "metadata": {
        "id": "FKcm_ZfYe4BO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove company, ltd etc from vendor names\n",
        "\n",
        "frag_list = ['company', 'ltd', 'inc', 'inc.', 'labs', 'gmbh']\n",
        "frag_filter_list = ['and', 'in', 'management', 'software', 'i', 'to']\n",
        "\n",
        "frag_vendorNames_list =[]\n",
        "for v_name in all_vendors_list:\n",
        "  # check for .inc or .Inc\n",
        "  if any( ele in v_name for ele in frag_list ):\n",
        "    fname = v_name.split(\" \")[0].rstrip(',')\n",
        "    if fname not in frag_filter_list:\n",
        "      frag_vendorNames_list.append(fname)\n",
        "      "
      ],
      "metadata": {
        "id": "4IHP8ocfe-6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern_prod_list = []\n",
        "for iprod in all_prods_list:\n",
        "  if isinstance(iprod, float):\n",
        "    continue\n",
        "  prd_list = iprod.split(\" \")\n",
        "  if (len(prd_list) == 1):\n",
        "    pattern_prod_list.append( [{\"TEXT\" : iprod}])\n",
        "  else:\n",
        "    tmp_list = []\n",
        "    for iwrd in prd_list:\n",
        "      tmp_list.append ({\"TEXT\" : iwrd})\n",
        "    pattern_prod_list.append(tmp_list)\n",
        "\n",
        "###\n",
        "prod_patterns = []\n",
        "for x in pattern_prod_list:\n",
        "  prod_patterns.append( {\"label\" : \"PRODUCT\", \"pattern\" : x })\n",
        "\n",
        "pattern_vendor_list = []\n",
        "for iprod in all_vendors_list:\n",
        "  if isinstance(iprod, float):\n",
        "    continue\n",
        "  prd_list = iprod.split(\" \")\n",
        "  if (len(prd_list) == 1):\n",
        "    pattern_vendor_list.append( [{\"TEXT\" : iprod}])\n",
        "  else:\n",
        "    tmp_list = []\n",
        "    for iwrd in prd_list:\n",
        "      tmp_list.append ({\"TEXT\" : iwrd})\n",
        "    pattern_vendor_list.append(tmp_list)\n",
        "\n",
        "###\n",
        "vendor_patterns = []\n",
        "for x in pattern_vendor_list:\n",
        "  vendor_patterns.append( {\"label\" : \"VENDOR\", \"pattern\" : x })"
      ],
      "metadata": {
        "id": "cPxVJ3C1e34p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Develop A Custom Entity Ruler Model***"
      ],
      "metadata": {
        "id": "0s-UnFdGfVd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()\n",
        "ruler = nlp.add_pipe(\"entity_ruler\")\n",
        "ruler.add_patterns(prod_patterns)\n",
        "ruler.add_patterns(vendFrag_patterns) \n",
        "ruler.add_patterns(vendor_patterns)\n",
        "ruler.add_patterns(cat_patterns)\n",
        "\n",
        "\n",
        "doc1 = nlp(str.lower(\"I want compare Apache Hama PageManager AppointMate should we buy them from Assembrix who sells Sports League Software \"))\n",
        "print([(ent.text, ent.label_) for ent in doc1.ents])\n",
        "\n",
        "# save customzied model to disk\n",
        "ruler.to_disk(\"./run1_all_patterns_may5.jsonl\")"
      ],
      "metadata": {
        "id": "XUPfDnVKffnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read Saved Model from Disk**\n",
        "\n"
      ],
      "metadata": {
        "id": "R74krDcMfttP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en import English\n",
        "from pathlib import Path\n",
        "\n",
        "fpath = Path(\"/content/drive/MyDrive/FBproject/run1_all_patterns_may5.jsonl\")\n",
        "\n",
        "nlp2 = English()\n",
        "ruler2 = nlp2.add_pipe(\"entity_ruler\").from_disk(fpath)\n",
        "\n",
        "doc2 = nlp2(str.lower(\"I want to buy PHPjabbers Equipment Rental Software from Microsoft\"))\n",
        "print([(ent.text, ent.label_) for ent in doc2.ents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iodw2UyUfwzn",
        "outputId": "0047a5bd-2d11-4333-ce9f-f0b956e3be91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('phpjabbers equipment rental software', 'VENDOR_FRAGMENT'), ('microsoft', 'VENDOR')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Text = 'Cheaper options than Salesforce' \n",
        "#Text = 'Is Flaticon the best product in Bug Tracking Software' \n",
        "#Text = \"Should we buy Web4Realty or some other product in HVAC Software \"\n",
        "#Text = 'compare Automilez and Valtari'\n",
        "Text = 'I want compare PageManager AppointMate should we buy them from Assembrix who sells Sports League Software '\n",
        "#Text = 'is Slack or Zoom or Google better?'\n",
        "\n",
        "doc3 = nlp2(str.lower(Text))\n",
        "print([(ent.text, ent.label_) for ent in doc3.ents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6ibNfOjfyLf",
        "outputId": "aed34a99-bca1-4d04-b8b6-c5ec0a25a698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('pagemanager', 'VENDOR_FRAGMENT'), ('appointmate', 'VENDOR_FRAGMENT'), ('we', 'VENDOR'), ('them', 'VENDOR'), ('sports league software', 'CATEGORY')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## production quality code\n",
        "\n",
        "from spacy.lang.en import English\n",
        "class QueryParse ():\n",
        "\n",
        "  def __init__(self):\n",
        "    self.nlp_model = English()\n",
        "    ruler = self.nlp_model.add_pipe(\"entity_ruler\").from_disk(\"./run1_all_patterns_may5.jsonl\")\n",
        "\n",
        "    \n",
        "  def parse_query (self, qry_request, context):\n",
        "    \"\"\"\n",
        "    parse user query\n",
        "    \"\"\"\n",
        "    doc = self.nlp_model(str.lower(qry_request))\n",
        "    phrase_list = []\n",
        "    label_list = []\n",
        "    comb_list = []\n",
        "    for ent in doc.ents:\n",
        "      phrase_list.append(ent.text)\n",
        "      label_list.append(ent.label_)\n",
        "      comb_list.append([ent.label_, ent.text])\n",
        "    \n",
        "    if len(label_list) == 1:\n",
        "      return comb_list[0]\n",
        "    \n",
        "    return comb_list\n"
      ],
      "metadata": {
        "id": "JdXY8w-tf4Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lab_service = QueryParse ( )\n",
        "xx = lab_service.parse_query (\"phpjabbers knowledge base builder\", 'xx')\n",
        "print (xx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVf_SQp5f_RN",
        "outputId": "2023efbf-4d04-40b5-9c10-5fdb442e754f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRODUCT', 'phpjabbers knowledge base builder']\n"
          ]
        }
      ]
    }
  ]
}